{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'15:33'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker import ScriptProcessor\n",
    "import sagemaker\n",
    "import  datetime\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "gpus_per_host_dict = {\n",
    "    'ml.p3.2xlarge': 1,\n",
    "    'p3.2xlarge': 1,\n",
    "    'ml.p3.8xlarge': 4,\n",
    "    'p3.8xlarge': 4,\n",
    "    'ml.p3.16xlarge': 8,\n",
    "    'p3.16xlarge': 8,\n",
    "    'p2.8xlarge': 8\n",
    "}\n",
    "\n",
    "timezone = datetime.timezone(datetime.timedelta(hours=-7))\n",
    "datetime.datetime.now(tz=datetime.timezone(datetime.timedelta(hours=-7))).strftime('%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.3 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Making sure we are using sagemaker version 2 \n",
    "!{sys.executable} -m pip install sagemaker -U -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting job names and bucket info\n",
    "\n",
    "\n",
    "training_job_basename = 'simclr-train'\n",
    "dev_bucket_name = 'simclr-dev' \n",
    "\n",
    "s3_raw_input_tr_images = 's3://data/raw/train/images'\n",
    "s3_training_input = 's3://data/processed/train/images'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.session.Session()\n",
    "region = sess.boto_region_name\n",
    "sm_boto_client = sess.boto_session.client(service_name='sagemaker')\n",
    "s3_boot_client = sess.boto_session.client(service_name='s3')\n",
    "sm_role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('us-west-2',\n",
       " 'arn:aws:iam::575348091205:role/service-role/AmazonSageMaker-ExecutionRole-20210616T173263')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region, sm_role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training in cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_re = '[-+]?[0-9]+[.]?[0-9]*([eE][-+]?[0-9]+)?'\n",
    "metric_definitions = [{'Name': 'weight_decay', 'Regex': f'^.+ train/weight_decay = ({metric_re})'},\n",
    "                      {'Name': 'total_loss'  , 'Regex': f'^.+ train/total_loss   = ({metric_re})'},\n",
    "                      {'Name': 'contrast_loss', 'Regex': f'^.+ train/contrast_loss = ({metric_re})'},\n",
    "                      {'Name': 'contrast_acc', 'Regex': f'^.+ train/contrast_acc = ({metric_re})'},\n",
    "                      {'Name': 'contrast_entropy', 'Regex': f'^.+ train/contrast_entropy = ({metric_re})'},\n",
    "                      {'Name': 'supervised_loss', 'Regex': f'^.+ train/supervised_loss = ({metric_re})'},\n",
    "                      {'Name': 'supervised_acc', 'Regex': f'^.+ train/supervised_acc = ({metric_re})'},\n",
    "                      {'Name': 'supervised_msens', 'Regex': f'^.+ train/supervised_msens = ({metric_re})'},\n",
    "                      {'Name': 'val_supervised_loss', 'Regex': f'^.+ val/supervised_loss = ({metric_re})'},\n",
    "                      {'Name': 'val_supervised_acc', 'Regex': f'^.+ val/supervised_acc = ({metric_re})'},\n",
    "                      {'Name': 'val_supervised_msens', 'Regex': f'^.+ val/supervised_msens = ({metric_re})'} \n",
    "                     ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using boto3 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from time import strftime\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "from smexperiments.tracker import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensembling.py\n",
      "Evaluate.py\n",
      "asymetric_loss.py\n",
      "feed.py\n",
      "model.py\n",
      "preprocess.py\n",
      "preprocessing/\n",
      "preprocessing/to_tfrecord.py\n",
      "preprocessing/folderize.py\n",
      "preprocessing/__init__.py\n",
      "preprocessingRefined.py\n",
      "requirements.txt\n",
      "resnet.py\n",
      "simclr_aug_util.py\n",
      "simclr_config.py\n",
      "simclr_data.py\n",
      "simclr_eval.py\n",
      "simclr_lars_opt.py\n",
      "simclr_metrics.py\n",
      "simclr_model.py\n",
      "simclr_objective.py\n",
      "simclr_run.py\n",
      "simclr_run_distrib.py\n",
      "stats.py\n",
      "train.py\n",
      "untitled.flow\n",
      "visualizer.py\n",
      "s3://simclr-isic-dev-oregon/code/test-smd-wd1e3-1-16xlarge-buff1-21-10-14-09h45m/sourcedir.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!tar -cvzf sourcedir.tar.gz -C src/  `ls src`\n",
    "\n",
    "base_h_params = {'seed': \"1234\",\n",
    "                 'train_epochs': \"100\",\n",
    "                 'train_epochs_finetune':\"10\",\n",
    "                 'train_batch_size':'32',\n",
    "                 'oversample':'True',     #'--nooversample', 'True'\n",
    "                 'oversample_f':'True',   #'--nooversample_f', 'True'\n",
    "                 'optimizer':'adam',\n",
    "                 'learning_rate':'0.001',\n",
    "                 'learning_rate_finetuning':'0.001',\n",
    "                 'use_step_decay':\"True\",  #'--nouse_step_decay', 'True'\n",
    "                 'num_proj_layers': '1',\n",
    "                 'ft_proj_selector':'0',\n",
    "                 'proj_head_mode': 'nonlinear',\n",
    "                 'pretrain_on_train_only': '--nopretrain_on_train_only', #'--nopretrain_on_train_only',\n",
    "                 'train_mode' : 'finetune',  #pretrain_then_finetune, finetune\n",
    "                 'base_weights': 'imagenet',  #imagenet, None\n",
    "                 'weight_decay': \"1e-3\",\n",
    "                 'distrib_library': \"smdistributed\"  # 'None', 'horovod', 'smdistributed'\n",
    "                }\n",
    "base_h_params.update({'hparams_header': \",\".join(list(base_h_params.keys()))})  #list of HP parameters as shown in Tensorboard\n",
    "\n",
    "timestamp = datetime.datetime.now(tz=timezone).strftime('-%y-%m-%d-%Hh%Mm')\n",
    "\n",
    "training_instance_type = 'ml.p3.16xlarge' # ml.p3.16xlarge #'ml.g4dn.2xlarge' | 'ml.m4.xlarge'|'ml.m4.2xlarge'|'ml.m4.4xlarge'|'ml.m4.10xlarge'|'ml.m4.16xlarge'|'ml.g4dn.xlarge'|'ml.g4dn.2xlarge'|'ml.g4dn.4xlarge'|'ml.g4dn.8xlarge'|'ml.g4dn.12xlarge'|'ml.g4dn.16xlarge'|'ml.m5.large'|'ml.m5.xlarge'|'ml.m5.2xlarge'|'ml.m5.4xlarge'|'ml.m5.12xlarge'|'ml.m5.24xlarge'|'ml.c4.xlarge'|'ml.c4.2xlarge'|'ml.c4.4xlarge'|'ml.c4.8xlarge'|'ml.p2.xlarge'|'ml.p2.8xlarge'|'ml.p2.16xlarge'|'ml.p3.2xlarge'|'ml.p3.8xlarge'|'ml.p3.16xlarge'|'ml.p3dn.24xlarge'|'ml.p4d.24xlarge'|'ml.c5.xlarge'|'ml.c5.2xlarge'|'ml.c5.4xlarge'|'ml.c5.9xlarge'|'ml.c5.18xlarge'|'ml.c5n.xlarge'|'ml.c5n.2xlarge'|'ml.c5n.4xlarge'|'ml.c5n.9xlarge'|'ml.c5n.18xlarge',\n",
    "instance_count = 1\n",
    "\n",
    "t_job_name = 'test-smd-wd1e3-1-16xlarge-buff1'+timestamp   #training_job_basename+timestamp\n",
    "\n",
    "s3_code=sess.upload_data(path='sourcedir.tar.gz', \n",
    "                         bucket = dev_bucket_name, \n",
    "                         key_prefix='code/'+t_job_name\n",
    "                        )\n",
    "print(s3_code)\n",
    "\n",
    "processes_per_host = gpus_per_host_dict[training_instance_type]\n",
    "distributed = True\n",
    "h_parameters = base_h_params\n",
    "h_parameters.update({\n",
    "    'sagemaker_submit_directory': s3_code,    \n",
    "    'sagemaker_container_log_level': \"20\",\n",
    "    'sagemaker_enable_cloudwatch_metrics': \"true\",\n",
    "    'sagemaker_job_name': t_job_name,\n",
    "    'sagemaker_region': region,    \n",
    "    'sagemaker_program': \"simclr_run_distrib.py\", \n",
    "    's3_tensorboard_uri': f\"s3://{dev_bucket_name}/model/tensorboard/logs_distrib/\" + t_job_name\n",
    "})\n",
    "\n",
    "if base_h_params['distrib_library'] == \"horovod\":\n",
    "    h_parameters.update({'sagemaker_mpi_custom_mpi_options': \"-verbose --NCCL_DEBUG=INFO -x OMPI_MCA_btl_vader_single_copy_mechanism=none\",\n",
    "                         'sagemaker_mpi_enabled': str(distributed),\n",
    "                         \"sagemaker_mpi_num_of_processes_per_host\": str(processes_per_host)\n",
    "                        })\n",
    "    \n",
    "elif base_h_params['distrib_library'] == \"smdistributed\":\n",
    "    h_parameters.update({'sagemaker_mpi_custom_mpi_options':\"-verbose --NCCL_DEBUG=INFO -x OMPI_MCA_btl_vader_single_copy_mechanism=none\",\n",
    "                         'sagemaker_distributed_dataparallel_enabled': str(distributed)\n",
    "                        })    \n",
    "\n",
    "\n",
    "s3_base_output_uri = f\"s3://{dev_bucket_name}/model/checkpoints/\" \n",
    "s3_checkpoints = s3_base_output_uri + t_job_name\n",
    "\n",
    "training_container_img= sagemaker.image_uris.retrieve(framework=\"tensorflow\", \n",
    "                                                        image_scope='training',\n",
    "                                                        version='2.4', \n",
    "                                                        region='us-west-2',\n",
    "                                                        instance_type=training_instance_type,\n",
    "                                                        py_version='py37'\n",
    "                                                        )\n",
    "response = sm_boto_client.create_training_job(\n",
    "                TrainingJobName=t_job_name,\n",
    "                RoleArn=sm_role,\n",
    "                AlgorithmSpecification={\n",
    "                    'TrainingImage': training_container_img,\n",
    "                    'TrainingInputMode': 'File',\n",
    "                    'EnableSageMakerMetricsTimeSeries': True,\n",
    "                    'MetricDefinitions': metric_definitions\n",
    "                },\n",
    "                InputDataConfig=[{'ChannelName': 'train',\n",
    "                                  'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
    "                                                                  'S3Uri': f'{s3_isic_training_input}/folderized',\n",
    "                                                                  'S3DataDistributionType': 'FullyReplicated'}},\n",
    "                                                },\n",
    "                                ],\n",
    "                HyperParameters=h_parameters,\n",
    "                OutputDataConfig={'KmsKeyId': '',\n",
    "                                  'S3OutputPath': s3_base_output_uri}, #SM automatically adds jobname/output/ to this URI\n",
    "                ResourceConfig={'InstanceType': training_instance_type,\n",
    "                                'InstanceCount': instance_count,\n",
    "                                'VolumeSizeInGB': 200},\n",
    "                StoppingCondition={'MaxRuntimeInSeconds': 86400},\n",
    "                CheckpointConfig = {\n",
    "                    \"S3Uri\": s3_checkpoints\n",
    "                }\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensembling.py\n",
      "Evaluate.py\n",
      "asymetric_loss.py\n",
      "feed.py\n",
      "model.py\n",
      "preprocess.py\n",
      "preprocessing/\n",
      "preprocessing/to_tfrecord.py\n",
      "preprocessing/folderize.py\n",
      "preprocessing/__init__.py\n",
      "preprocessingRefined.py\n",
      "requirements.txt\n",
      "resnet.py\n",
      "simclr_aug_util.py\n",
      "simclr_config.py\n",
      "simclr_data.py\n",
      "simclr_eval.py\n",
      "simclr_lars_opt.py\n",
      "simclr_metrics.py\n",
      "simclr_model.py\n",
      "simclr_objective.py\n",
      "simclr_run.py\n",
      "stats.py\n",
      "train/\n",
      "train/.gitignore\n",
      "train.py\n",
      "visualizer.py\n",
      "s3://simclr-isic-dev-oregon/code/eval-job-21-10-04-12h06m/sourcedir.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!tar -cvzf sourcedir.tar.gz -C src/  `ls src`\n",
    "\n",
    "\n",
    "jn = \"evaluation\"\n",
    "\n",
    "base_h_params = {'seed': \"1234\",\n",
    "                 'oversample':'False',   \n",
    "                 'oversample_f':'False',   \n",
    "                }\n",
    "\n",
    "timestamp = datetime.datetime.now(tz=timezone).strftime('-%y-%m-%d-%Hh%Mm')\n",
    "\n",
    "eval_instance_type = 'ml.p3.2xlarge' #'ml.g4dn.2xlarge' | 'ml.m4.xlarge'|'ml.m4.2xlarge'|'ml.m4.4xlarge'|'ml.m4.10xlarge'|'ml.m4.16xlarge'|'ml.g4dn.xlarge'|'ml.g4dn.2xlarge'|'ml.g4dn.4xlarge'|'ml.g4dn.8xlarge'|'ml.g4dn.12xlarge'|'ml.g4dn.16xlarge'|'ml.m5.large'|'ml.m5.xlarge'|'ml.m5.2xlarge'|'ml.m5.4xlarge'|'ml.m5.12xlarge'|'ml.m5.24xlarge'|'ml.c4.xlarge'|'ml.c4.2xlarge'|'ml.c4.4xlarge'|'ml.c4.8xlarge'|'ml.p2.xlarge'|'ml.p2.8xlarge'|'ml.p2.16xlarge'|'ml.p3.2xlarge'|'ml.p3.8xlarge'|'ml.p3.16xlarge'|'ml.p3dn.24xlarge'|'ml.p4d.24xlarge'|'ml.c5.xlarge'|'ml.c5.2xlarge'|'ml.c5.4xlarge'|'ml.c5.9xlarge'|'ml.c5.18xlarge'|'ml.c5n.xlarge'|'ml.c5n.2xlarge'|'ml.c5n.4xlarge'|'ml.c5n.9xlarge'|'ml.c5n.18xlarge',\n",
    "\n",
    "instance_count = 1  \n",
    "\n",
    "eval_job_name = 'eval-job'+timestamp   #training_job_basename+timestamp\n",
    "\n",
    "s3_code=sess.upload_data(path='sourcedir.tar.gz', \n",
    "                         bucket = dev_bucket_name, \n",
    "                         key_prefix='code/'+eval_job_name\n",
    "                        )\n",
    "print(s3_code)\n",
    "\n",
    "processes_per_host = 1 #gpus_per_host_dict[training_instance_type]\n",
    "\n",
    "h_parameters = base_h_params\n",
    "h_parameters.update({\n",
    "    'sagemaker_submit_directory': s3_code,    \n",
    "    'sagemaker_container_log_level': \"20\",\n",
    "    'sagemaker_enable_cloudwatch_metrics': \"true\",\n",
    "    'sagemaker_job_name': eval_job_name,\n",
    "    'sagemaker_region': region,    \n",
    "    'sagemaker_program': \"simclr_eval.py\"\n",
    "})\n",
    " \n",
    "training_container_img= sagemaker.image_uris.retrieve(framework=\"tensorflow\", \n",
    "                                                        image_scope='training',\n",
    "                                                        version='2.4', \n",
    "                                                        region='us-west-2',\n",
    "                                                        instance_type=training_instance_type,\n",
    "                                                        py_version='py37'\n",
    "                                                        )\n",
    "response = sm_boto_client.create_training_job(\n",
    "                TrainingJobName=eval_job_name,\n",
    "                RoleArn=sm_role,\n",
    "                AlgorithmSpecification={\n",
    "                    'TrainingImage': training_container_img,\n",
    "                    'TrainingInputMode': 'File',\n",
    "                    'EnableSageMakerMetricsTimeSeries': True,\n",
    "                    'MetricDefinitions': metric_definitions\n",
    "                },\n",
    "                InputDataConfig=[{'ChannelName': 'train',\n",
    "                                  'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
    "                                                                  'S3Uri': f'{s3_isic_training_input}/folderized',\n",
    "                                                                  'S3DataDistributionType': 'FullyReplicated'}},\n",
    "                                                },\n",
    "                                 {'ChannelName': 'model_to_eval',\n",
    "                                  'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
    "                                                                  'S3Uri': f's3://simclr-isic-dev-oregon/model/checkpoints/{jn}/final_model/{jn}/output/model.tar.gz',\n",
    "                                                                  'S3DataDistributionType': 'FullyReplicated'}},\n",
    "                                                },\n",
    "                                ],\n",
    "                HyperParameters=h_parameters,\n",
    "                OutputDataConfig={'KmsKeyId': '',\n",
    "                                  'S3OutputPath': s3_checkpoints + \"final_model/\"},\n",
    "                ResourceConfig={'InstanceType': training_instance_type,\n",
    "                                'InstanceCount': instance_count,\n",
    "                                'VolumeSizeInGB': 200},\n",
    "                StoppingCondition={'MaxRuntimeInSeconds': 86400},\n",
    "                CheckpointConfig = {\n",
    "                    \"S3Uri\": s3_checkpoints\n",
    "                }\n",
    "#                ExperimentConfig = {\n",
    "#                \"TrialName\" : demo_trial.trial_name,\n",
    "#                \"TrialComponentDisplayName\" : \"TrainingJob\",\n",
    "#                }\n",
    "           )"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
